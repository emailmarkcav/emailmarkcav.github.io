---
layout: page
title: Data Science Workbench
permalink: /dsworkbench/
---

Data science teams need an environment that allows them to connect with stakeholders, gain context fast, work through data at scale (beyond their PCs), and publish, share, and enable others to make data-driven decisions. Luckly we are at point where most the technologies, tools and techniques are open sourced (see below), given us more time to focus on the domain, the problem, the people, the process. Ultimately, the latter makes a more effective data science team. 

# What is a data science workbench?
My 94 year old grandfather (Vern) had a workbench in his garage. I was in love with his space. He made wooden sailboats,toys, furniture, fixed wobbly chairs...whatever grandmas needs were, he figured it out. He seemed to have the right tools, at the right place, at the time right. I was inspired by this. Back to us. With proven problem solving methodologies (DMAIC & Six Sigma have been around since 1980s) and open source technology, advancement in machine learning and data everywhere... having a data science workbench is critical. Data science teams tasks range from asking right questions, gaining domain knowledge, assessing opportunities/problems, and acquiring the right data, tools, technologies to enable an effective solutions. Below I will attempt to document the end-to-end range of task for a data science team and provide how-to's, code-examples, open source resources, and general overall playbook.

# Tasks above-average data science teams do well...

| Tasks     | Description   | Tools & Technologies|Training|
|-----------|-------------|-------------------|-------|
| Identify opportunities or problems    |   Gain context of products, processes, key decisions, and control points| Interviews, SWOT, SIPOC, Process Mapping, Affinity Mapping, Ishikawa diagram, FMEA,QFD,KPIs        |  TBD     |
| Define problem and measure impact    | Understand urgency, severity, complexity, and business impact. Should be convincing in order to gain suppoer and resources (if needed)           |   Problem Statement Guidelines, Avoid Solutioning      |  TBD     |
| Set a business goal for project   |  Goals can be incremental or transformative (or both). Understanding impact if goal is not met can help determine level of precision/accuracy/scalabilty against cost. |   SMART goals, Benchmarking, Normality Test     |  TBD     |
| Prioritize Problems / Opportunities   |  Gain business alignment on priorities |   Prioritization Matrix, Cause and Effect Matrix     |  TBD     |
|Acquire data   |   Ability to ingest data from various data sources| Webscrapping, APIs, Sensors, B2B feeds, Audio, Images, SQL and NoSQL languages |  TBD     |
| Store data  | select right database technology, create/design tables, write data, and create data model (make data consumeable) | Postgres, Pgadmin4, MongoDB, SAP Hana, Hadoop, Cloud Storage|  TBD     |
| Access and transform data   | Ability to query data tables & join, aggregate, clean, validate useable dataset| SQL and NoSQL (MongoDB aggregation), Python, Notebooks, Pandas, Numpy, Loops, Excel    |  TBD    |
| Automate data pipelines    | Schedule datasets to be automatically updated/refreshed | Cron, Windows Task Scheduler, Airflow     |  TBD     |
| Visualize Data   | Ability to interpret and ask questions of dataset to gain context of domain    |   Tableau, Spotfire, Google Data Studio, Seaborn, Plotly, Matplotlib   |  TBD     |
| Identify key variables   | Determine relationships and correlations of variables and effect on response variable / control point          | EDA, Correlation Matrix, Covariance, ANOVA, t-test, Histograms, I-MR Charts, Kruskal-Wallis Test, Multi-Vari Chart, Density Plots, Normal Probability Plot, Pareto Charts, p chart, Regression, Root Sum of Sqaures, Run Chart, Scatter plot, Xbar-R charts        |  TBD     |
| Select and Build M.L. Models   | Ability to select effective model to address objectives/goal           | Classification, Regression, Clustering, Optimization, Decision-Tree, Bayesian Trees, Neutral Nets, Distance Formulas, scikit-learn, caret, tensorflow      |  TBD     |
| Implement effective containerization and Virtual environments   | Ability to contain experiments and projects within a local environment to avoid version conflicts. Also makes projects portable/shareable       |   Docker, DockerHub, virtualenv |  TBD     |
| Understand compute & HW limits   | Understand trade-off of time and cost regarding computational power  | GPUs vs CPUs, Differentiable programming (e.g Tensorflow), Cloud Services, Distributed Computing (e.g Dask), Kubernetes     |  TBD    |
| Document and Storytell  | Ability to articulate approach, findings, challenges, results to both collegues and business leaders through written and verbal communication  | github, git, markdown, Tableau, powerpoint, research paper template | TBD     |
| Package solution | Make solution useful. Build minimum-vaiable product (MVP) for consumer/user to interact with solutions          |  Flask, Dash, Ploty, RShiny, Tableau | TBD    |
| Measure Change Management   | Ability to assess adoption of solution and recieve feedback | Stakeholder Analysis, Performance and Compliance Metrics, Data Collection Plan, Surveys, Audits, Marketing and Communication Plan  |  TBD     | 
{:.mbtablestyle}
